{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libs\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import RandomRotation, RandomWidth, RandomHeight, RandomZoom, RandomBrightness, RandomContrast, GaussianNoise, RandomFlip, Rescaling, Resizing, RandomCrop\n",
    "from keras_cv.layers import RandomShear, RandomSaturation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplica Data Augmentation Layer (Keras 3.x e KerasCV) $\\\\$ Em imagens de uma pasta e salva em outra pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Layer\n",
    "im_size = (256, 256)  # Define the desired image size\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomSaturation((0.4, 0.6)),  # Adjust saturation\n",
    "    RandomRotation(0.15, fill_mode='nearest', fill_value=0),  # Random rotation\n",
    "    RandomWidth(0.01),  # Width shift\n",
    "    RandomHeight(0.01),  # Height shift\n",
    "    RandomShear(0.01, fill_mode='nearest', fill_value=0),  # Shear\n",
    "    RandomZoom(0.01, 0.01, fill_mode='nearest', fill_value=0),  # Zoom\n",
    "    RandomBrightness(factor=0.1),  # Brightness\n",
    "    RandomContrast(factor=0.1),  # Contrast\n",
    "    GaussianNoise(0.1),  # Gaussian noise\n",
    "    RandomFlip(mode=\"horizontal_and_vertical\"),  # Random flip\n",
    "    tf.keras.layers.Resizing(im_size[0], im_size[1]),  # Resize to im_size\n",
    "])\n",
    "\n",
    "# Directories\n",
    "input_dir = 'C:\\\\cascade\\\\frutas\\\\p_train_old'\n",
    "output_dir = 'C:\\\\cascade\\\\frutas\\\\banana_train\\\\p_train_aug'\n",
    "total_augmented_images = 40000  # Total number of augmented images to generate\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to process and save images\n",
    "def process_and_save_image(image_path, output_dir, num_augmented, img_counter):\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "    img_array = np.array(image)  # Convert to numpy array\n",
    "\n",
    "    # Create a TensorFlow tensor from the numpy array\n",
    "    img_tensor = tf.convert_to_tensor(img_array)\n",
    "\n",
    "    for i in range(num_augmented):\n",
    "        # Apply data augmentation\n",
    "        augmented_img = data_augmentation(tf.expand_dims(img_tensor, axis=0))  # Add batch dimension\n",
    "        \n",
    "        # Convert the augmented tensor back to a PIL Image\n",
    "        augmented_img = Image.fromarray(augmented_img[0].numpy().astype(np.uint8))  # Remove batch dimension\n",
    "        \n",
    "        # Save the augmented image to the output directory\n",
    "        augmented_img.save(os.path.join(output_dir, f\"augmented_image_{img_counter}.jpg\"))\n",
    "        img_counter += 1\n",
    "\n",
    "    return img_counter\n",
    "\n",
    "# Function to iterate over the image directory and process each image\n",
    "def process_image_directory(input_dir, output_dir, total_augmented_images):\n",
    "    img_filenames = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    num_original_images = len(img_filenames)\n",
    "\n",
    "    # Calculate how many images to generate per original image\n",
    "    images_per_file = total_augmented_images // num_original_images\n",
    "    extra_images = total_augmented_images % num_original_images  # Handle remainder\n",
    "    \n",
    "    img_counter = 0\n",
    "    while img_counter < total_augmented_images:\n",
    "        for img_filename in img_filenames:\n",
    "            img_path = os.path.join(input_dir, img_filename)\n",
    "\n",
    "            # Adjust for any extra images that need to be generated\n",
    "            num_augmented = images_per_file + 1 if extra_images > 0 else images_per_file\n",
    "            extra_images = max(0, extra_images - 1)  # Decrease extra count after using it\n",
    "\n",
    "            img_counter = process_and_save_image(img_path, output_dir, num_augmented, img_counter)\n",
    "            \n",
    "            # Stop if we've reached the target number of augmented images\n",
    "            if img_counter >= total_augmented_images:\n",
    "                break\n",
    "\n",
    "# Process the input directory and save results\n",
    "process_image_directory(input_dir, output_dir, total_augmented_images)\n",
    "\n",
    "print(f\"Processing complete. Augmented images saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gera Patches (Crop) de Imagens grandes com Data Augmentation Layer (Keras 3.x e KerasCV) $\\\\$ Em imagens de uma pasta e salva em outra pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "input_dir = 'C:\\\\cascade\\\\frutas\\\\banana_test\\\\n'\n",
    "output_dir = 'C:\\\\cascade\\\\frutas\\\\banana_test\\\\n_crop'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to process and save images\n",
    "def process_and_save_image(image_path, output_dir, crop_size=(256, 256)):\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "    img_array = np.array(image)  # Convert to numpy array\n",
    "    img_height, img_width = img_array.shape[:2]  # Get image dimensions\n",
    "\n",
    "    # If the image is <= 256x256, just copy it without changes\n",
    "    if img_height <= crop_size[0] and img_width <= crop_size[1]:\n",
    "        image.save(os.path.join(output_dir, os.path.basename(image_path)))\n",
    "    else:\n",
    "        # Create a TensorFlow tensor from the numpy array\n",
    "        img_tensor = tf.convert_to_tensor(img_array)\n",
    "\n",
    "        # Calculate how many crops to apply (1 crop if larger, 2 crops if 2x larger)\n",
    "        crop_times = 1 if (img_height <= crop_size[0] * 2 and img_width <= crop_size[1] * 2) else 2\n",
    "\n",
    "        for i in range(crop_times):\n",
    "            # Ensure the image is larger than the crop size\n",
    "            if img_height > crop_size[0] and img_width > crop_size[1]:\n",
    "                # Apply random cropping\n",
    "                cropped_img = tf.image.random_crop(img_tensor, size=[crop_size[0], crop_size[1], img_tensor.shape[2]])\n",
    "\n",
    "                # Convert the cropped tensor back to a PIL Image\n",
    "                cropped_img = Image.fromarray(cropped_img.numpy())\n",
    "\n",
    "                # Save the cropped image to the output directory\n",
    "                cropped_img.save(os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_crop_{i}.jpg\"))\n",
    "            else:\n",
    "                print(f\"Image {image_path} is not large enough for cropping.\")\n",
    "\n",
    "# Function to iterate over the image directory and process each image\n",
    "def process_image_directory(input_dir, output_dir):\n",
    "    for img_filename in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, img_filename)\n",
    "        \n",
    "        # Only process image files (skip non-image files)\n",
    "        if img_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            process_and_save_image(img_path, output_dir)\n",
    "\n",
    "# Process the input directory and save results\n",
    "process_image_directory(input_dir, output_dir)\n",
    "\n",
    "print(f\"Processing complete. Cropped images saved in: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
